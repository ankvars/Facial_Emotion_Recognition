# -*- coding: utf-8 -*-
"""Project_Emotion_recog_image.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WH9cVzMsBqLrGC0phD4LJf61X4o2a87D
"""

mport numpy as np

# Run this cell to mount your Google Drive.
#dataset should be there in drive (csv file)
from google.colab import drive
drive.mount('/content/drive')

# import pandas as pd
# file=pd.read_csv('/content/drive/My Drive/CODING/fer2013.csv')
# test_file=pd.read_csv('/content/drive/My Drive/CODING/testck.csv')

# Importing csv files from Drive 
#file is for reading fer2013 datasets csv file
# test_file is for reading ck+ datasets csv file
import pandas as pd
file=pd.read_csv('/content/drive/My Drive/fer2013.csv')
test_file=pd.read_csv('/content/drive/My Drive/testck.csv')

# fl['emotion']
# print('file=',file)
print('file=',file)
print('test_file=',test_file)
# emotion=file['emotion']
# pixels=file['pixels']
# Usage=file['Usage']
# print('emotion=',emotion[0])
# print('pixel[0]=',pixels[0])
# print('Usage[0]=',Usage[0])

# !pwd

# type(pixels)

#code to fetch all the data from imported csv files
#x and y
X=[]
Y=[]
for i in range(file.shape[0]):
  l=file.iloc[i,1].split()
  l=[float(ele) for ele in l] 
#   print('len=',len(l))
  print(i)
#   if file.iloc[i,2] == "Training":
  X.append(np.array(l).reshape(48,48))
  Y.append(file.iloc[i,0])

# test_file

#code to fetch all the data from imported csv files
# y_test=[]
# x_test=[]
# X=[]
# Y=[]
for i in range(test_file.shape[0]):
    l=test_file.iloc[i,1].split(",")
#     print(type(l[0]))
    print('i=',i)

    l=[float(ele) for ele in l] 
#     print(i)
    X.append(np.array(l).reshape(48,48))
    Y.append(test_file.iloc[i,0])

#printing the data X and Y and corresponding shape
X=np.asarray(X)
Y=np.asarray(Y)


print('X.shape=',X.shape)
print('Y.shape=',Y.shape)



# normalizing the data

def normalize(x):
     # Normalize inputs to (0,1)
#     print(x.shape)
    print(x[0],x[1],x[2])
    x_n = x/255.
    return x_n
X = normalize(X)

#resahape image-pixels  inputs to classify to grayscale (3 ,if rgb)
def reshape(x):
    x_r=x.reshape(x.shape[0],x.shape[1],x.shape[2],1)
    print(x_r.shape)
    return x_r
X = reshape(X)

# x_train = reshape(x_train)
# x_test = reshape(x_test) 
# x_val = reshape(x_val)

#one hot encoding
def oneHot(y, Ny):
    
    from keras.utils import to_categorical 
    y_oh=to_categorical(y,num_classes=Ny)
    return y_oh

# example
Y = oneHot(Y,7)

# y_train = oneHot(y_train,7)
# y_test = oneHot(y_test,7) 
# y_val = oneHot(y_val,7)

# from sk

# splitting the whole data to train and test
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(X,Y, test_size=0.1,random_state=1)

# # from keras import model
# from keras.models import load_model
# loaded_model=load_model('best_model_weights.hdf5')

#give equal weightage to all the classes present in data
from sklearn.utils import class_weight
class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.argmax(1)), y_train.argmax(1))

# class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train.argmax(1)), y_train.argmax(1))
# model.fit(X_train, y_train, class_weight=class_weights)
# print('x_train[0]=',x_train[0])
# # print('x_test[0]=',x_test[0])



#cnn sequential model creation
from keras import optimizers
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.layers import Conv2D, AveragePooling2D
model = Sequential()
 
#1st convolution layer
model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))
model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))
 
#2nd convolution layer
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))
 
#3rd convolution layer
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(Conv2D(128, (3, 3), activation='relu'))

model.add(MaxPooling2D(pool_size=(3,3), strides=(2, 2)))
 
model.add(Flatten())
 
#fully connected neural networks
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.2))
 
model.add(Dense(7, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(), metrics=['accuracy'])

model.summary()

#training model
from keras.callbacks import ModelCheckpoint
checkpointer = ModelCheckpoint(filepath="best_model_weights.hdf5", verbose=1, save_best_only=True)
# hist = model.fit(..., callbacks=[checkpointer])
# model.load_weights('weights.hdf5')
history = model.fit(x_train, y_train, validation_split=0.1,epochs=25, batch_size=200, callbacks=[checkpointer], class_weight=class_weights)

# history = model.fit(x_train, y_train, validation_data=(x_val, y_val),epochs=25, batch_size=200, callbacks=[checkpointer], class_weight=class_weights)
model.load_weights('best_model_weights.hdf5')
# history = model.fit(x_train, y_train, validation_split = 0.1, epochs=2, batch_size=200)

# Use 10% of samples for validation, validation_split is the relevant parameter

#svaing best model
from keras.models import load_model
loaded_model=load_model('best_model_weights.hdf5')

#output prediction
def predict(x):
    
    y=loaded_model.predict(x)
    return y

def oneHot_tolabel(y):
    
    y_b = np.argmax(y,axis=1)
    np.asarray(y_b)
    return y_b
# oneHot_tolabel(train_labels)

y_pred=loaded_model.predict(x_train)

def create_confusion_matrix(true_labels, predicted_labels):
    
#     print('predicted_labels=',predicted_labels.shape)
#     print()

    from sklearn.metrics import confusion_matrix
    
    cm = confusion_matrix(y_train.argmax(axis=1), y_pred.argmax(axis=1))
    return cm

# cm = create_confusion_matrix(train_labels,predict(train_samples))
cm = create_confusion_matrix(oneHot_tolabel(y_train), oneHot_tolabel(predict(x_train)))

print(cm)
# print(class_weights)

# x_test_fer=[]
# y_test_fer=[]
# for i in range(file.shape[0]):
#   l=file.iloc[i,1].split()
#   l=[float(ele) for ele in l] 
# #   print('len=',len(l))
#   print(i)
# #   if file.iloc[i,2] == "Training":
#   x_test_fer.append(np.array(l).reshape(48,48))
#   y_test_fer.append(file.iloc[i,0])
  

# x_test_fer=np.array(x_test_fer)
# y_test_fer=np.array(y_test_fer)

# cm_test=create_confusion_matrix(oneHot_tolabel(y_test),oneHot_tolabel(predict(x_test)))
# # cm_test=create_confusion_matrix(oneHot_tolabel(y_test_fer),oneHot_tolabel(predict(x_test_fer)))

# print('test_confusion_matrix')
# print(cm_test)

history.history.keys()
import matplotlib.pyplot as plt
plt.plot(range(len(history.history['val_acc'])), history.history['val_acc'])
plt.show()

# # x_test
# # y_test
# x_test_fer=reshape(x_test_fer)
# y_test_fer=oneHot(y_test_fer, 7)

def accuracy(x_test, y_test, model):
    
    loss,acc=model.evaluate(x_test,y_test,verbose=0)
    return acc

# acc = accuracy(x_test_fer, y_test_fer, model)

acc = accuracy(x_test, y_test, model)
print('Test accuracy is, ', acc*100, '%')

wrong=list(np.nonzero(model.predict(x_test).argmax(1)!= y_test.argmax(1)))[0]
# print('y_test.argmax(1)=',y_test.argmax(1))
# type(wrong)
# print('wrong=',wrong)
# print('wrong=',len(wrong))

emotion_ls=['Angry', 'Disgust', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral']
# anger=0, disgust=1, fear=2, happy=3, sad=4, surprise=5, neutral=6

emotion_ls=['Angry', 'Disgust', 'Fear', 'Happy','Sad', 'Surprise', 'Neutral']
import numpy as np
correct=[20,2,46]
index=np.arange(7)
# emotions=pd.file.iloc[]
y_pred=model.predict (x_test)
def plot_img(i):
#   %matplotlib inline
  import matplotlib.pyplot as plt
#   print(x_test.shape)
  x=x_test[i]
  x=x.reshape(48,48)
  pixels=x
  plt.imshow(pixels,cmap='gray')
  plt.show()
  print('label of img is ',emotion_ls[y_test[i].argmax()])
  print('pred of img is ',emotion_ls[y_pred[i].argmax()])
  print('y_pred=',y_pred[i])
#   print('Label of image is', em[xx[i]],' predicted ',em[yy[i]])
  plt.bar(index, y_pred[i])
  plt.xlabel('Emotions', fontsize=10)
  plt.ylabel('probability distribution ', fontsize=10)
  plt.xticks(index, emotion_ls, fontsize=10, rotation=30)
  plt.title('Distribution of emotions')
  plt.show()
  
  
# for i in wrong:
for i in correct:
  plot_img(i)

index=np.arange(7)
ls=[0,1,2,5,34,57]
# emotions=pd.file.iloc[]
y_pred=model.predict (x_test)
def plot_img(i):
#   %matplotlib inline
  import matplotlib.pyplot as plt
#   print(x_test.shape)
  x=x_test[i]
  x=x.reshape(48,48)
  pixels=x
  plt.imshow(pixels,cmap='gray')
  plt.show()
  print('label of img is ',emotion_ls[y_test[i].argmax()])
  print('pred of img is ',emotion_ls[y_pred[i].argmax()])
  print('y_pred=',y_pred[i])
#   print('Label of image is', em[xx[i]],' predicted ',em[yy[i]])
  plt.bar(index, y_pred[i])
  plt.xlabel('Emotions', fontsize=10)
  plt.ylabel('probability distribution ', fontsize=10)
  plt.xticks(index, emotion_ls, fontsize=10, rotation=30)
  plt.title('Distribution of emotions')
  plt.show()
  
# for i in wrong:
for i in ls:
#   print(i)
#   if i==3 or i==4:
#     continue
  plot_img(wrong[i])

#

